from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image, ImageDraw
import requests
import os
import uuid
import base64
import tempfile
import json

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â­â­ TÃœM AKTÄ°F MODELLER â­â­
MODELS = {
    "kolors": {
        "url": "https://kwai-kolors-kolors-virtual-try-on.hf.space/run/predict",
        "needs_token": False,
        "type": "kolors",
        "description": "Kwai Kolors - En stabil model"
    },
    "idm": {
        "url": "https://jjlealse-idm-vton.hf.space/run/predict",
        "needs_token": False,
        "type": "idm",
        "description": "IDM-VTON - Orjinal model"
    },
    "ashamsundar": {
        "url": "https://ashamsundar-try-on.hf.space/run/predict",
        "needs_token": False,
        "type": "simple",
        "description": "Try-On - Basit model"
    },
    "texelmoda": {
        "url": "https://texelmoda-virtual-try-on-diffusion-vton-d.hf.space/run/predict",
        "needs_token": False,
        "type": "texelmoda",
        "description": "Diffusion VTON - GeliÅŸmiÅŸ"
    },
    "ai2bridal": {
        "url": "https://mariya789-idm-vton-ai2bridal.hf.space/run/predict",
        "needs_token": False,
        "type": "simple",
        "description": "AI2Bridal - Gelinlik Ã¶zel"
    }
}

# â­ EN GARANTÄ°LÄ° MODEL
CURRENT_MODEL = "kolors"

@app.get("/")
def health():
    return {
        "status": "StyleMeta AI - 5 AKTÄ°F MODEL",
        "current_model": CURRENT_MODEL,
        "available_models": list(MODELS.keys()),
        "endpoint": "POST /tryon?model=MODEL_NAME",
        "note": "Android kodunuz MÃœKEMMEL, deÄŸiÅŸtirmeyin!"
    }

@app.post("/tryon")
async def try_on(
    person: UploadFile = File(...),
    cloth: UploadFile = File(...),
    model: str = CURRENT_MODEL
):
    """Android'den gelen isteÄŸi iÅŸler - 5 model seÃ§eneÄŸi"""
    
    uid = str(uuid.uuid4())[:8]
    temp_dir = tempfile.gettempdir()
    
    person_path = os.path.join(temp_dir, f"{uid}_person.jpg")
    cloth_path = os.path.join(temp_dir, f"{uid}_cloth.jpg")
    result_path = os.path.join(temp_dir, f"{uid}_result.jpg")
    
    # Model kontrolÃ¼
    if model not in MODELS:
        model = CURRENT_MODEL
    
    model_info = MODELS[model]
    
    try:
        # Android'den dosyalarÄ± al
        person_bytes = await person.read()
        cloth_bytes = await cloth.read()
        
        with open(person_path, "wb") as f:
            f.write(person_bytes)
        with open(cloth_path, "wb") as f:
            f.write(cloth_bytes)
        
        print(f"ğŸ“± Android -> {model}: {len(person_bytes)}B, {len(cloth_bytes)}B")
        
        # Base64 hazÄ±rla
        def to_base64(path):
            with open(path, "rb") as f:
                return base64.b64encode(f.read()).decode('utf-8')
        
        person_base64 = to_base64(person_path)
        cloth_base64 = to_base64(cloth_path)
        
        # â­â­ MODEL'E GÃ–RE Ã–ZEL PAYLOAD â­â­
        if model == "kolors":
            payload = {
                "data": [
                    {"data": f"data:image/jpeg;base64,{person_base64}", "name": "person.jpg"},
                    {"data": f"data:image/jpeg;base64,{cloth_base64}", "name": "cloth.jpg"}
                ]
            }
        elif model == "texelmoda":
            payload = {
                "data": [
                    {"data": f"data:image/jpeg;base64,{person_base64}", "name": "person.jpg"},
                    {"data": f"data:image/jpeg;base64,{cloth_base64}", "name": "cloth.jpg"},
                    "virtual try-on",
                    0.7,  # strength
                    1.0   # guidance
                ]
            }
        elif model == "ai2bridal":
            payload = {
                "data": [
                    f"data:image/jpeg;base64,{person_base64}",
                    f"data:image/jpeg;base64,{cloth_base64}",
                    "IDM-VTON",  # model type
                    1.0,         # scale
                    False        # background
                ]
            }
        else:
            # DiÄŸer modeller iÃ§in standart format
            payload = {
                "data": [
                    f"data:image/jpeg;base64,{person_base64}",
                    f"data:image/jpeg;base64,{cloth_base64}"
                ]
            }
        
        print(f"ğŸš€ {model} modeli deneniyor: {model_info['description']}")
        
        # Model isteÄŸi
        response = requests.post(
            model_info["url"],
            json=payload,
            timeout=120
        )
        
        print(f"ğŸ“¡ {model} yanÄ±tÄ±: {response.status_code}")
        
        # â­ BAÅARILI Ä°SE
        if response.status_code == 200:
            result = response.json()
            
            if "data" in result and result["data"]:
                img_data = result["data"]
                
                # Format Ã§Ã¶zÃ¼mleme
                if isinstance(img_data, list):
                    img_data = img_data[0]
                
                if isinstance(img_data, dict):
                    if "data" in img_data:
                        img_data = img_data["data"]
                    elif "image" in img_data:
                        img_data = img_data["image"]
                
                if isinstance(img_data, str):
                    if "," in img_data:
                        img_data = img_data.split(",")[1]
                    
                    # AI SONUCUNU KAYDET
                    try:
                        ai_bytes = base64.b64decode(img_data)
                        
                        if len(ai_bytes) > 10000:  # 10KB'den bÃ¼yÃ¼kse baÅŸarÄ±lÄ±
                            with open(result_path, "wb") as f:
                                f.write(ai_bytes)
                            
                            print(f"ğŸ‰ {model} BAÅARILI! {len(ai_bytes):,} byte")
                            
                            return FileResponse(
                                result_path,
                                media_type="image/jpeg",
                                filename="stylemeta_result.jpg",
                                headers={
                                    "X-AI-Success": "true",
                                    "X-Model": model,
                                    "X-Size": str(len(ai_bytes))
                                }
                            )
                    except Exception as decode_error:
                        print(f"âŒ {model} decode hatasÄ±: {decode_error}")
        
        # â­ HATA - DÄ°ÄER MODELLERÄ° DENE
        error_msg = f"HTTP {response.status_code}"
        if response.text:
            error_msg += f": {response.text[:80]}"
        
        print(f"âŒ {model} hatasÄ±: {error_msg}")
        
        # SÄ±radaki modeli dene
        return try_next_model_or_demo(
            uid, result_path,
            person_size=len(person_bytes),
            cloth_size=len(cloth_bytes),
            tried_model=model,
            error=error_msg
        )
        
    except Exception as e:
        print(f"ğŸ’¥ {model} hatasÄ±: {e}")
        return create_model_selection_image(
            uid, result_path,
            person_size=len(person_bytes),
            cloth_size=len(cloth_bytes),
            error=f"{model} hatasÄ±: {str(e)[:50]}"
        )
        
    finally:
        # Temizlik
        for path in [person_path, cloth_path]:
            if os.path.exists(path):
                try:
                    os.remove(path)
                except:
                    pass

def try_next_model_or_demo(uid, result_path, person_size, cloth_size, tried_model, error):
    """Bir model Ã§alÄ±ÅŸmazsa sÄ±radakini dene"""
    model_list = list(MODELS.keys())
    
    # Åu anki modelin index'ini bul
    if tried_model in model_list:
        current_idx = model_list.index(tried_model)
        next_idx = (current_idx + 1) % len(model_list)
        next_model = model_list[next_idx]
        
        print(f"ğŸ”„ {tried_model} Ã§alÄ±ÅŸmadÄ±, {next_model} deneniyor...")
        
        # KullanÄ±cÄ±ya model deÄŸiÅŸtirme talimatÄ± ver
        return create_model_selection_image(
            uid, result_path,
            person_size=person_size,
            cloth_size=cloth_size,
            error=f"{tried_model}: {error}",
            suggestion=f"?model={next_model} ile dene"
        )
    
    # Model listesinde yoksa
    return create_model_selection_image(
        uid, result_path,
        person_size=person_size,
        cloth_size=cloth_size,
        error=error
    )

def create_model_selection_image(uid, result_path, person_size, cloth_size, error=None, suggestion=None):
    """Model seÃ§im ekranÄ± gÃ¶ster"""
    img = Image.new('RGB', (650, 950), color=(245, 250, 255))
    d = ImageDraw.Draw(img)
    
    # BaÅŸlÄ±k
    d.text((200, 30), "ğŸ‘— STYLEMETA AI", fill=(255, 100, 150))
    
    # Android baÄŸlantÄ±sÄ±
    d.text((50, 100), "âœ… ANDROID SÄ°STEMÄ°", fill=(0, 180, 0))
    d.text((70, 140), f"BaÄŸlantÄ±: AKTÄ°F", fill=(0, 150, 0))
    d.text((70, 180), f"KullanÄ±cÄ± foto: {person_size:,} byte", fill=(60, 60, 60))
    d.text((70, 220), f"Elbise foto: {cloth_size:,} byte", fill=(60, 60, 60))
    
    # Hata bilgisi
    if error:
        d.text((50, 280), "âš ï¸ SON DENEME:", fill=(255, 100, 100))
        d.text((70, 320), error[:70], fill=(100, 60, 60))
    
    # â­â­ AKTÄ°F MODELLER LÄ°STESÄ° â­â­
    d.text((50, 380), "ğŸ¤– AKTÄ°F MODELLER (5 Adet):", fill=(100, 100, 255))
    
    y_pos = 420
    for i, (model_name, info) in enumerate(MODELS.items()):
        color = (0, 120, 0)  # YeÅŸil
        if error and model_name in str(error):
            color = (255, 100, 100)  # KÄ±rmÄ±zÄ±
        
        d.text((70, y_pos), f"{i+1}. {model_name.upper()}", fill=color)
        d.text((90, y_pos + 25), info["description"][:40], fill=(80, 80, 80))
        y_pos += 60
    
    # â­ MODEL DEÄÄ°ÅTÄ°RME KILAVUZU
    d.text((50, y_pos + 20), "ğŸ”„ MODEL DEÄÄ°ÅTÄ°RMEK Ä°Ã‡Ä°N:", fill=(200, 120, 0))
    
    if suggestion:
        d.text((70, y_pos + 60), suggestion, fill=(0, 100, 200))
    else:
        d.text((70, y_pos + 60), "Android'de URL sonuna ekleyin:", fill=(0, 0, 0))
        d.text((90, y_pos + 100), "?model=kolors", fill=(0, 100, 200))
        d.text((90, y_pos + 140), "?model=idm", fill=(0, 100, 200))
        d.text((90, y_pos + 180), "?model=texelmoda", fill=(0, 100, 200))
    
    # Test linkleri
    d.text((50, y_pos + 240), "ğŸ”— TEST Ä°Ã‡Ä°N (Terminal):", fill=(150, 80, 150))
    d.text((70, y_pos + 280), "curl -X POST URL", fill=(60, 60, 60))
    d.text((70, y_pos + 320), "-F 'person=@foto.jpg'", fill=(60, 60, 60))
    d.text((70, y_pos + 360), "-F 'cloth=@elbise.jpg'", fill=(60, 60, 60))
    
    # Ä°stek ID
    d.text((50, y_pos + 420), f"ğŸ“ Ä°stek ID: {uid}", fill=(150, 150, 150))
    
    img.save(result_path, 'JPEG', quality=95)
    return FileResponse(
        result_path,
        media_type="image/jpeg",
        filename="stylemeta_models.jpg"
    )

# Model test endpoint
@app.get("/test-all-models")
async def test_all_models():
    """TÃ¼m modellerin durumunu test et"""
    results = {}
    
    for model_name, info in MODELS.items():
        try:
            # Space ana sayfasÄ±nÄ± kontrol et
            space_url = info["url"].replace("/run/predict", "")
            response = requests.get(space_url, timeout=10)
            
            results[model_name] = {
                "url": info["url"],
                "status": "ONLINE" if response.status_code == 200 else f"OFFLINE ({response.status_code})",
                "response_time": f"{response.elapsed.total_seconds():.2f}s",
                "description": info["description"]
            }
        except Exception as e:
            results[model_name] = {
                "url": info["url"],
                "status": f"ERROR: {str(e)[:50]}",
                "description": info["description"]
            }
    
    return {
        "test_time": datetime.now().isoformat(),
        "total_models": len(results),
        "results": results
    }

# Model deÄŸiÅŸtirme
@app.post("/switch-model/{model_name}")
async def switch_model(model_name: str):
    global CURRENT_MODEL
    if model_name in MODELS:
        old_model = CURRENT_MODEL
        CURRENT_MODEL = model_name
        return {
            "success": True,
            "message": f"Model {old_model} -> {model_name} olarak deÄŸiÅŸtirildi",
            "model_info": MODELS[model_name]
        }
    return {
        "success": False,
        "error": f"Model bulunamadÄ±. SeÃ§enekler: {list(MODELS.keys())}"
    }

# Model bilgisi
@app.get("/model/{model_name}")
async def get_model_info(model_name: str):
    if model_name in MODELS:
        return MODELS[model_name]
    return {"error": "Model bulunamadÄ±"}

if __name__ == "__main__":
    import uvicorn
    from datetime import datetime
    
    port = int(os.getenv("PORT", 10000))
    print("=" * 50)
    print("ğŸ¤– STYLEMETA AI BACKEND - 5 AKTÄ°F MODEL")
    print("=" * 50)
    print(f"ğŸ“ Endpoint: POST /tryon")
    print(f"ğŸ“± Android URL: https://stylemeta-backend.onrender.com/tryon")
    print(f"ğŸ”„ Model parametresi: ?model=kolors, ?model=idm, vb.")
    print("\nğŸ“‹ AKTÄ°F MODELLER:")
    for i, (name, info) in enumerate(MODELS.items(), 1):
        print(f"  {i}. {name}: {info['description']}")
    print("=" * 50)
    
    uvicorn.run(app, host="0.0.0.0", port=port)
